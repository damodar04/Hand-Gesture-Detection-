# ğŸ–ï¸ Hand Gesture Control System

**Control your entire computer using just your hand gestures â€” no touch, no mouse, just movement!**  
A Computer Vision + Python project for hands-free control of **volume, brightness, screenshots, apps, and more**.

---

## ğŸš€ Project Overview

The **Hand Gesture Control System** uses real-time **hand tracking** to interpret gestures and perform computer actions.  
With the power of **OpenCV**, **MediaPipe**, and **PyAutoGUI**, your **webcam** becomes a smart controller â€”  
allowing you to interact with your PC naturally and efficiently.

---

## âœ¨ Features

| ğŸ’¡ Feature | ğŸ¯ Description |
|------------|----------------|
| ğŸšï¸ **Volume Control** | Control system volume using finger distance. |
| ğŸŒ **Brightness Control** | Adjust screen brightness with simple gestures. |
| ğŸ“¸ **Screenshot Capture** | Take instant screenshots with a specific hand pose. |
| ğŸ—‚ï¸ **App & File Launching** | Open applications or files using gestures. |
| ğŸ”„ **Glove Mode** | Works with or without a glove for accuracy. |
| ğŸ§  **AI-Powered Detection** | Uses MediaPipeâ€™s hand landmark model for precise gesture tracking. |

---

## ğŸ§© Project Structure

hand-gesture-control/
â”œâ”€â”€ app.py â†’ Main application entry point
â”œâ”€â”€ Gesture_Controller.py â†’ Core gesture detection and system control
â”œâ”€â”€ Gesture_Controller_Gloved.pyâ†’ Gesture detection version for glove input
â”œâ”€â”€ 4bytes.py â†’ Helper or utility script
â”œâ”€â”€ tempCodeRunnerFile.py â†’ Temporary file used during development
â”œâ”€â”€ LICENSE â†’ License file
â””â”€â”€ README.md â†’ Project documentation


---

## ğŸ› ï¸ Technologies Used

| Technology | Purpose |
|-------------|----------|
| ğŸ **Python 3.8+** | Core programming language |
| ğŸ‘ï¸ **OpenCV** | Real-time image & video processing |
| âœ‹ **MediaPipe** | Hand landmark detection & tracking |
| ğŸ–±ï¸ **PyAutoGUI** | System control automation |
| ğŸ”Š **pycaw** | Audio control |
| ğŸ’¡ **screen-brightness-control** | Brightness management |
| ğŸ”¢ **NumPy** | Mathematical computations |

---

## ğŸ§  How It Works

1. The webcam continuously captures live video frames.  
2. **MediaPipe** identifies **21 hand landmarks** in real time.  
3. Detected gestures (like finger positions or distances) are mapped to specific computer actions.  
4. **PyAutoGUI** executes those system-level tasks like controlling volume, brightness, taking screenshots, etc.

**Examples of Gestures:**

| Gesture | Action |
|----------|---------|
| ğŸ–ï¸ | Move mouse cursor |
| âœŒï¸ | Capture screenshot |
| ğŸ‘ | Increase volume |
| ğŸ‘ | Decrease volume |

---

## ğŸ”’ License

This project is licensed under the **MIT License** â€” see the [LICENSE](./LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Damodar Bhawsar**  
ğŸ’¼ *Data Science & Automation Enthusiast*  
ğŸ“§ **damodar.7974@gmail.com**  
ğŸ”— [GitHub Profile](https://github.com/damodar04)

---

## â­ Acknowledgements

- [MediaPipe by Google](https://developers.google.com/mediapipe)  
- [PyAutoGUI Documentation](https://pyautogui.readthedocs.io/)  
- [OpenCV](https://opencv.org/)

---

â­ **If you like this project, donâ€™t forget to star it on GitHub!**
